# 八、数据库集成 II

在本章中，我们将了解如何使用成熟的 RDBMS 系统 MySQL。然后，我们将研究两个数据库抽象层，PDO 和 ADOdb。在本章的最后，我们将向您展示如何利用 Sphinx 文本搜索引擎。

对于 MySQL 数据库，有几个 PHP 扩展可供选择。最常用的是 MySQL 扩展。这个扩展很老了，没有面向对象，因为它从 PHP4 和 MySQL 4 就存在了。它还缺少一些重要的特性，比如绑定变量。还有一个更新的扩展，MySQLi，将在本章中介绍。值得一提的是，旧的、过程化的 MySQL 扩展仍然是最常用的。

### MySQLi 扩展简介

MySQLi 扩展在许多方面类似于上一章讨论的 SQLite3 扩展。它也是面向对象的，不像旧的 MySQL 扩展那样是过程化的，也不像 SQLite3 那样抛出异常。除了数据库之外，组件是相同的，在这种情况下，数据库比 SQLite 强大得多，并支持全套 ANSI 标准数据库特性。出于本章的目的，MySQL 版运行在本地机器上:

`mysql -u scott --password=tiger scott
Reading table information for completion of table and column names
You can turn off this feature to get a quicker startup with -A

Welcome to the MySQL monitor. Commands end with ; or \g.
Your MySQL connection id is 50
Server version: 5.1.37-1ubuntu5.5 (Ubuntu)

Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.

mysql> select version();
+-------------------+
| version()         |
+-------------------+
| 5.1.37-1ubuntu5.5 |
+-------------------+
1 row in set (0.00 sec)`

用户名是“scott”，密码是“tiger”，数据库名是“scott”数据库结构将与 SQLite3 示例中的相同:我们将拥有相同的“emp”和“dept”表。我们还将使用相同的两个脚本:一个用于将 CSV 文件加载到数据库中，另一个用于运行查询。重写相同的脚本建立了比较的基础，并使不同 MySQLi 方法的目的非常清楚。以下是 MySQL 风格的表格描述:

`mysql> describe emp;
+----------+-------------+------+-----+-------------------+---------------------+
| Field    | Type        | Null | Key | Default           | Extra                |
+----------+-------------+------+-----+-------------------+---------------------+
| empno  | int(4)                | NO   | PRI   | NULL       |                    |
| ename  | varchar(10)      | YES  |         | NULL        |                    |
| job        | varchar(9)        | YES  |         | NULL        |                    |
| mgr       | int(4)               | YES  |         | NULL        |                    |
| hiredate| timestamp        | NO    |         | CURRENT_TIMESTAMP  |
| sal         | double             | YES  |         | NULL        |                     |
| comm   | double              | YES  |         | NULL        |                    |
| deptno  | int(4)                | YES  | MUL | NULL       |                    |
+----------+-------------+------+-----+-----------------------+-----------------+
8 rows in set (0.00 sec)

mysql> describe dept;
+----------+-----------------+------+-----+---------+-------+
| Field     | Type            | Null | Key | Default | Extra|
+----------+-----------------+------+-----+---------+--------+
| deptno  | int(4)           | NO   | PRI | NULL   |          |
| dname  | varchar(14) | YES |         | NULL   |          |
| loc        | varchar(13) | YES  |       | NULL    |          |
+----------+-----------------+------+-----+----------+-------+
3 rows in set (0.00 sec)`

表是空的，还有两个 CSV 文件要加载到数据库中。CSV 代表“逗号分隔值”，是一种标准的表格文件格式，可被 SQL 数据库和电子表格程序(如 Microsoft Excel)识别。事实上，大多数数据库都有特殊规定，允许更容易地加载 CSV 文件。这适用于 MySQL，它有`LOAD DATA`命令，如下例所示。然而，我们的脚本仍然是一个很好的练习。下面是`LOAD DATA` MySQL 命令的语法描述:

`mysql> help load data
Name: 'LOAD DATA'
Description:
Syntax:
LOAD DATA [LOW_PRIORITY | CONCURRENT] [LOCAL] INFILE 'file_name'
    [REPLACE | IGNORE]
    INTO TABLE tbl_name
    [CHARACTER SET charset_name]
    [{FIELDS | COLUMNS}
        [TERMINATED BY 'string']
        [[OPTIONALLY] ENCLOSED BY 'char']
        [ESCAPED BY 'char']
    ]` 
`    [LINES
        [STARTING BY 'string']
        [TERMINATED BY 'string']
    ]
    [IGNORE number LINES]
    [(col_name_or_user_var,...)]
    [SET col_name = expr,...]`

要加载的文件将被命名为 emp.csv 和 dept.csv 文件与第七章中的版本略有不同。这是因为与 MySQL 不同，SQLite 不支持日期类型。MySQL 支持完整的 ANSI 标准数据类型和数据算法。为了加载时间戳类型的数据，我们必须使用正确的日期格式，即 YYYY-MM-DD HH24:MI-SS。YYYY 部分表示四位数的年份，MM 是月份，DD 是一个月中的某一天，HH24 是 24 小时制的小时，MI 和 SS 是分钟和秒钟。以下是文件:

`***emp.csv***

7369,SMITH,CLERK,7902,"1980-12-17 00:00:00",800,,20
7499,ALLEN,SALESMAN,7698,"1981-02-20 00:00:00",1600,300,30
7521,WARD,SALESMAN,7698,"1981-02-22 00:00:00",1250,500,30
7566,JONES,MANAGER,7839,"1981-04-02 00:00:00",2975,,20
7654,MARTIN,SALESMAN,7698,"1981-09-28 00:00:00",1250,1400,30
7698,BLAKE,MANAGER,7839,"1981-05-01 00:00:00",2850,,30
7782,CLARK,MANAGER,7839,"1981-06-09 00:00:00",2450,,10
7788,SCOTT,ANALYST,7566,"1987-04-19 00:00:00",3000,,20
7839,KING,PRESIDENT,,"1981-11-17 00:00:00",5000,,10
7844,TURNER,SALESMAN,7698,"1981-09-08 00:00:00",1500,0,30
7876,ADAMS,CLERK,7788,"1987-05-23 00:00:00",1100,,20
7900,JAMES,CLERK,7698,"1981-12-03 00:00:00",950,,30
7902,FORD,ANALYST,7566,"1981-12-03 00:00:00",3000,,20
7934,MILLER,CLERK,7782,"1982-01-23 00:00:00",1300,,10`

“dept”文件与第七章中的版本相同:

`***dept.csv***

10,ACCOUNTING,"NEW YORK"
20,RESEARCH,DALLAS
30,SALES,CHICAGO
40,OPERATIONS,BOSTON`

创建表格的脚本没有任何有趣的元素。用于执行“创建表”命令的所有调用都包含在加载和查询数据的脚本中。清单 8-1 显示了将两个 CSV 文件加载到各自的 MySQL 表中的脚本。

***清单 8-1。**将两个 CSV 文件加载到各自的 MySQL 表中*

`<?php
if ($argc != 3) {
    die("USAGE:script8.1 <table_name> <file name>\n");
}
$tname = $argv[1];` `$fname = $argv[2];
$rownum = 0;
function create_insert_stmt($table, $ncols) {
    $stmt = "insert into $table values(";
    foreach (range(1, $ncols) as $i) {
        $stmt.= "?,";
    }
    $stmt = preg_replace("/,$/", ')', $stmt);
    return ($stmt);
}
try {
    $db = new mysqli("localhost", "scott", "tiger", "scott");
    $db->autocommit(FALSE);
    $res = $db->prepare("select * from $tname");
    if ($db->errno != 0) {
        throw new Exception($db->error);
    }
    $ncols = $res->field_count;
    $res->free_result();
    $ins = create_insert_stmt($tname, $ncols);
    $fmt = str_repeat("s", $ncols);
    $res = $db->prepare($ins);
    if ($db->errno != 0) {
        throw new Exception($db->error);
    }
    $fp = new SplFileObject($fname, "r");
    while ($row = $fp->fgetcsv()) {
        if (strlen(implode('', $row)) == 0) continue;
        array_unshift($row, $fmt);
        foreach(range(1,$ncols) as $i) {
            $row[$i]=&$row[$i];
        }
        call_user_func_array(array(&$res, "bind_param"), &$row);
        $res->execute();
        if ($res->errno != 0) {
            print_r($row);
            throw new Exception($res->error);
        }
        $rownum++;
    }
    $db->commit();
    if ($db->errno != 0) {
        throw new Exception($db->error);
    }
    print "$rownum rows inserted into $tname.\n";
}
catch(Exception $e) {
    print "Exception:\n";
    die($e->getMessage() . "\n");
}
?>`

这个剧本里有不少有趣的元素。连接到数据库不是其中之一。创建新的 MySQLi 实例的参数是主机名、用户名、密码和要连接的数据库。此语句将关闭自动提交模式:

`$db->autocommit(FALSE);`

MySQL 是一个完整的关系数据库，支持事务和 ACID 需求，正如在第七章中所解释的。`COMMIT`语句是一个 ANSI SQL 语句，它使当前事务的效果永久化。相反的命令是`ROLLBACK`，它将取消当前交易的效果。在自动提交模式下，数据库会在每个 SQL 语句后发出`COMMIT`，比如 insert。`COMMIT`语句的开销非常大，因为按照 ACID 要求，会话必须等到所需的信息被物理写入磁盘后才能继续。不仅该语句非常昂贵和耗时，自动打开提交可能会导致部分加载，这通常是不希望的。好的程序员希望纠正问题，重新开始加载。

![images](img/square.jpg) **注意**关闭自动提交是所有关系数据库的常见做法。当脚本包含`INSERT`、`UPDATE`或`DELETE`语句时使用。自动提交是一项开销非常大的操作。

与 SQLite 的情况一样，我们将使用一个`select * from table` SQL 语句来找出有多少列。要执行的第一个调用是`prepare`:

`$res = $db->prepare("select * from $tname");`

这将解析 SQL 语句，并将其转换为类`MYSQLI_STMT`的对象，一个解析的语句。`MYSQLI_STMT`属性之一是包含字段的数量:

`$ncols = $res->field_count;`

当列数已知时，可以使用`free_result`调用并构造 insert 语句来关闭这个结果集。用来做这件事的函数与清单 7-9 中使用的同名函数非常相似，但并不相同。不同之处在于，插入现在看起来像这样:

`insert into dept values(?,?,?)`

它有问号，而不是占位符名称`:1`、`:2`和`:3`，如清单 7-9 中的所示。原因是 MySQLi 接口不支持命名绑定，只支持位置绑定。所有绑定必须同时完成，将一个值数组绑定到解析后的语句。语句绑定方法具有以下格式:

`$res->bind_param("fmt",$var1,$var2,$var3,...,$varN);`

第一个参数是格式字符串，它是由每个绑定变量的一个字符组成的字符串。格式字符告诉 MySQLi 变量的类型，该变量被绑定到与它在参数数组中相同的位置。这意味着`$var1`被绑定到 insert 中的第一个位置，由第一个问号标记，$var2 被绑定到第二个问号，依此类推。格式字符串是“I”表示整数，“d”表示双精度数，“s”表示字符串，“b”表示 blob。Blobs 是二进制数据集合，就像图像一样。

我们现在有一个编程问题:我们必须在一个 PHP 语句中将变量绑定到 insert 语句，而不知道我们必须绑定多少个变量。格式化字符串很简单——我们只需构造一个由所有字符串组成的字符串。PHP 等弱类型脚本语言的一个好处是类型通常不是大问题；几乎所有东西都可以转换成字符串。对于`bind_param`方法，我们必须使用一些诡计。幸运的是，PHP 在技巧方面非常通融。有一个 PHP 函数叫做`call_user_func_array`，调用第一个参数中命名的用户函数，用第二个参数中的 array 作为参数数组。如果我们有一个带三个参数(`$a1,$a`和`$a3)`)的函数`F(),`，那么表达式`F($a1,$a2,$a3)`将完全等价于表达式`call_user_func_array("F",array($a1,$a2,$a3))`。如果函数`F()`是对象`$obj`的一个方法，那么第一个参数将是`array($obj,"F")`而不仅仅是“f”。这将在任何 PHP 版本中解决这个问题，直到 5.3。不幸的是，在 PHP 5.3 版本中，MySQLi 期望绑定变量的引用，并且不接受值。这就是脚本中包含以下代码片段的原因:

`array_unshift($row, $fmt);
foreach(range(1,$ncols) as $i) {
           $row[$i]=&$row[$i];
}`

我们确保每个绑定变量都包含对实际值的引用。这不是指格式字符串。循环中的`range`从 1 开始，在`unshift`之后，格式位于数组的开头。PHP 数组以`index=0`开头，而不是前面代码片段中的 1 作为我们的“范围”函数，这意味着我们跳过了这个格式，把它作为一个值。在准备好我们的参数数组之后,“神奇的”绑定就这样完成了:

`call_user_func_array(array(&$res, "bind_param"), &$row);`

之后，执行解析后的语句`$res`。对于由`SplFileObject`从 CSV 文件返回的每一行，都重复这一过程。当所有行都被读取时，循环结束，执行`commit`。这是`commit`的逻辑位置。当然，正如本章开头所说，MySQLi 不抛出异常；使用它的程序员负责每个关键步骤后的错误检查。然而，MySQLi 已经为此做好了准备。所有 MySQLi 类的每个对象都有`errno`和`error`属性。`errno`属性是错误代码，`error`属性包含错误的文本描述。MySQLi 系统中有三个不同的类:`MYSQLi`本身，描述数据库连接；`MYSQLi_STMT`，描述解析后的语句；以及描述结果集的`MYSQLI_RESULT`，由数据库返回给脚本。清单 8-1 使用了连接和声明类。要查看结果类，我们必须检索一些数据(参见清单 8-2 )。

***清单 8-2。**写一份与清单 7-10* 相同的报告

`<?php
$QRY = "select e.ename,e.job,d.dname,d.loc
        from emp e join dept d on(d.deptno=e.deptno)";
$ncols = 0;
$colnames = array();
try {
    $db = new mysqli("localhost", "scott", "tiger", "scott");
    $res = $db->query($QRY);
    print "\n";
    if ($db->errno != 0) {
        throw new Exception($db->error);
    }` `    // Get the number of columns
    $ncols = $res->field_count;

    // Get the column names
    while ($info = $res->fetch_field()) {
        $colnames[] = strtoupper($info->name);
    }

    // Print the column titles
    foreach ($colnames as $c) {
        printf("%-12s", $c);
    }

    // Print the border
    printf("\n%s\n", str_repeat("-", 12 * $ncols));

    // Print rows
    while ($row = $res->fetch_row()) {
        foreach (range(0, $ncols - 1) as $i) {
            printf("%-12s", $row[$i]);
        }
        print "\n";
    }
}
catch(Exception $e) {
    print "Exception:\n";
    die($e->getMessage() . "\n");
}
?>`

该脚本将编写一份与清单 7-10 中的脚本相同的报告。脚本结构与清单 7-10 相同。注意，这里不需要关闭自动提交；此脚本中没有事务。

connection 类的“query”方法返回一个`MYSQLI_RESULT`类的对象，在本例中恰当地命名为`$res`。该对象的属性之一是列数:

`$ncols = $res->field_count;`

对于每一列，都有一个描述——一个辅助类`stdClas`的对象。该对象通过使用`$res`对象的`fetch_field`方法来检索。以下是相关片段:

`while ($info = $res->fetch_field()) {
        $colnames[] = strtoupper($info->name);
    }`

这个脚本只使用了“name”属性，但是包含在`$info`对象中的整个描述如下所示:

`stdClass Object
(
    [name] => empno
    [orgname] => empno
    [table] => emp
    [orgtable] => emp` `    [def] =>
    [max_length] => 4
    [length] => 4
    [charsetnr] => 63
    [flags] => 53251
    [type] => 3
    [decimals] => 0
)`

“name”属性显然指的是列名。在处理视图时，`orgname`和`orgtable`很重要。SQL 标准描述了称为“视图”的对象，这些对象本质上是命名查询。允许查询重命名列，因此新名称将在“name”属性中，而原始名称和表将在`orgname`和`orgtable`属性中。除了名称和长度列之外，最重要的列是类型列。不幸的是，MySQLi 文档中没有记录这些类型的含义。然而，根据经验，我们知道 3 是整数，5 是双精度数，253 是可变字符，7 是时间戳数据类型。

就像所有其他数据库一样，有一个“fetch”调用从数据库中获取结果。在这种情况下，该方法被称为`fetch_row`。获取数据的循环与清单 7-10 中的 SQLite 示例完全相同:

`while ($row = $res->fetch_row()) {
        foreach (range(0, $ncols - 1) as $i) {
            printf("%-12s", $row[$i]);
        }
        print "\n";
    }`

这个脚本的输出看起来与清单 7-10 中的输出完全一样:

`./script8.2.php
ENAME      JOB               DNAME           LOC
--------------------------------------------------- -----------------
CLARK       MANAGER    ACCOUNTING  NEW YORK
KING         PRESIDENT   ACCOUNTING  NEW YORK
MILLER     CLERK           ACCOUNTING  NEW YORK
SMITH       CLERK           RESEARCH      DALLAS
JONES       MANAGER     RESEARCH      DALLAS
SCOTT      ANALYST       RESEARCH      DALLAS
ADAMS     CLERK           RESEARCH      DALLAS
FORD        ANALYST       RESEARCH      DALLAS
ALLEN        SALESMAN    SALES       CHICAGO
WARD        SALESMAN    SALES       CHICAGO
MARTIN      SALESMAN    SALES       CHICAGO
BLAKE        MANAGER     SALES       CHICAGO
TURNER     SALESMAN    SALES       CHICAGO
JAMES        CLERK           SALES       CHICAGO`

#### MySQLi 扩展的结论

MySQL 比最初的 MySQL 扩展更加现代和强大，但它缺少一些重要的功能，如命名绑定和异常处理。许多托管公司只允许原始的 MySQL 扩展，它被更大、更好、更快的 MySQL 所取代。好在这个不是唯一的选择。还有 PDO 扩展家族，它解决了命名绑定和异常的问题。我们接下来将讨论 PDO 扩展。

### PDO 简介

PDO 是 PHP 数据对象的缩写。它试图将所有数据库的扩展统一到一个单一的编程应用接口(API)中，这将简化编程并减少编写与数据库交互的应用所需的知识量。这种努力对一些数据库来说是成功的，但对其他数据库来说就不那么成功了。当一切都简化为相同的公分母时，一些特殊的功能就会丢失，例如 PostgreSQL 或数组接口中的“复制”命令以及 Oracle RDBMS 的会话池。这些功能旨在显著加快数据处理速度，但无法通过 PDO 获得。此外，数据库供应商主要维护特定于数据库的扩展，这使得 PDO 有些被忽视。

PDO 有两层。首先，有一个通用的 PDO 接口，然后有一个特定于数据库的驱动程序，它与 PDO 层合作，与数据库进行实际的交互。默认情况下启用 PDO，但是需要单独安装数据库驱动程序。PDO 接口实际上比本地接口更好的数据库之一是 MySQL。所以让我们看看用 PDO 写的 CSV 加载脚本(见清单 8-3 )。

***清单 8-3。**使用 PDO 编写的 CSV 加载脚本*

`<?php
if ($argc != 3) {
    die("USAGE:script8.3 <table_name> <file name>\n");
}
$tname = $argv[1];
$fname = $argv[2];
$rownum = 0;
function create_insert_stmt($table, $ncols) {
    $stmt = "insert into $table values(";
    foreach (range(1, $ncols) as $i) {
        $stmt.= "?,";
    }
    $stmt = preg_replace("/,$/", ')', $stmt);
    return ($stmt);
}
try {
    $db = new PDO('mysql:host=localhost;dbname=scott', 'scott', 'tiger');
    $db->setAttribute(PDO::ATTR_ERRMODE, PDO::ERRMODE_EXCEPTION);
    $res = $db->prepare("select * from $tname");
    $res->execute();
    $ncols = $res->columnCount();
    $ins = create_insert_stmt($tname, $ncols);
    $res = $db->prepare($ins);
    $fp = new SplFileObject($fname, "r");
    $db->beginTransaction();` `    while ($row = $fp->fgetcsv()) {
        if (strlen(implode('', $row)) == 0) continue;
        $res->execute($row);
        $rownum++;
    }
    $db->commit();
    print "$rownum rows inserted into $tname.\n";
}
catch(PDOException $e) {
    print "Exception:\n";
    die($e->getMessage() . "\n");
}
?>`

这是迄今为止最短的版本，但功能齐全。大部分缺失的代码是错误处理代码。这个版本的脚本中明显没有这段代码。原因是数据库连接后立即进行了`setAttribute`调用。在这个`setAttribute`调用中，PDO 被指示在出现任何数据库错误时抛出一个`PDOException`类的对象。该异常包含错误代码和消息，可用于处理错误。这使得我们所有定制的错误处理代码变得不必要，所以它被从脚本中删除了。

将变量绑定到占位符或语句的代码也完全不存在。PDO 可以在执行时执行绑定，这是它与我们的下一个可移植数据库接口 ADOdb 共有的特性。`execute`方法将绑定值的数组作为参数，并在执行之前将数组绑定到解析的语句。与清单 8-1 中绑定变量所必需的可怕的`call_user_func_array`魔法相比。PDO 确实支持命名占位符的`bindValue`方法，但并不经常需要。

在这个脚本中，我们还看到了“公分母”方法的一个缺陷:PDO 无法关闭会话的自动提交模式。它可以显式启动事务，这当然会在事务期间关闭自动提交模式，而不是在会话期间。

此外，PDO 必须首先执行一个准备好的语句才能描述它。原生 MYSQLi 驱动不需要执行语句；我们能够对在清单 8-1 中准备好但没有执行的语句执行`field_count`。执行长时间运行的 SQL 语句可能会导致很大的延迟。如果要加载的表包含数亿条记录，执行初始 SQL 语句"`select * from $table`"可能需要几个小时才能完成。其原因在于酸的需求。ACID 需求向用户保证，在查询开始之前，他只能看到提交给数据库的更改。数据库必须重建查询开始后修改的行，并向用户显示查询开始前的行版本。如果底层表很大并且频繁修改，那么这可能是一个非常漫长的过程。另一种方法是锁定该表，并阻止任何人在查询期间修改它。不用说，如果访问的并发性是一个业务需求，那么这种策略是不会通过的。

人们将不得不求助于不可移植的技巧来解决这个问题。一种方法是像这样重写 SQL:"`select * from $table limit 1`"。这将只从数据库返回一行，因此无论表的大小如何，执行速度都要快得多。不幸的是，这不适用于 Oracle RDBMS，它不支持`LIMIT`选项，而是使用自己的`ROWNUM`结构。这个问题没有现成的解决办法。这就是使用 PDO 的风险。然而，大多数用户只使用一种或两种类型的数据库引擎(例如，只有 MySQL 和 PostgreSQL)，所以这通常不是一个大问题。

现在，让我们看看第二个脚本，通过运行一个固定查询产生的小报告(见清单 8-4 )。

***清单 8-4。**运行固定查询生成的报告*

`<?php
$QRY = "select e.ename,e.job,d.dname,d.loc
        from emp e join dept d on(d.deptno=e.deptno)";
$colnames = array();
$ncols = 0;
try {
    $db = new PDO('mysql:host=localhost;dbname=scott', 'scott', 'tiger');
    $db->setAttribute(PDO::ATTR_ERRMODE, PDO::ERRMODE_EXCEPTION);
    $res = $db->prepare($QRY);
    $res->execute();
    // Get the number of columns
    $ncols = $res->columnCount();
    // For every column, define format, based on the type
    foreach (range(0, $ncols - 1) as $i) {
        $info = $res->getColumnMeta($i);
        $colnames[] = $info['name'];
    }
    //  Print column titles, converted to uppercase.
    foreach ($colnames as $c) {
        printf("%-12s", strtoupper($c));
    }
    //  Print the boundary
    printf("\n%s\n", str_repeat("-", 12 * $ncols));
    //  Print row data
    while ($row = $res->fetch(PDO::FETCH_NUM)) {
        foreach ($row as $r) {
            printf("%-12s", $r);
        }
        print "\n";
    }
}
catch(PDOException $e) {
    print "Exception:\n";
    die($e->getMessage() . "\n");
}
?>`

这完全是标准的—这里没什么可看的。然而，有趣的是，用于描述光标的`getColumnMeta`方法，在手册中仍然被标记为实验性的，并被标记为“使用风险自担”。这个方法绝对至关重要；没有它将严重限制 PDO 的用途。然而，这种方法并不适用于所有数据库。例如，它不能在 Oracle 上运行。此方法生成的列描述如下所示:

`Array
(
    [native_type] => VAR_STRING
    [flags] => Array
        (
        )

    [table] => d
    [name] => loc
    [len] => 13
    [precision] => 0
    [pdo_type] => 2
)`

表名是“d”，因为该方法从我们的 SQL 中选择了表别名。正在执行的查询如下:

`$QRY = "select e.ename,e.job,d.dname,d.loc
               from emp e join dept d on(d.deptno=e.deptno)";`

在这个查询中，我们为 emp 表使用了别名“e ”,为 dept 表使用了别名“d ”,以便能够将连接条件从(`emp.deptno=dept.deptno`)缩短为更短且同样易于理解(数据库服务器)的形式(`e.deptno = d.deptno`)。`getColumnMeta`方法返回这个别名，而不是完整的表名。这不一定是一个错误，但是会使“table”字段变得不那么有用。此外，fetch 包含了`PDO::FETCH_NUM`选项，类似于我们在清单 7-10 中看到的 SQLite 示例。就像这里的情况一样，fetch 可以将 row 作为由数字、列名索引的数组返回，或者作为以列名为属性的对象返回。默认为`FETCH_BOTH`，它将获取关联数组和数字索引数组。

提到 SQLite，SQLite3 也有一个 PDO 驱动程序。更重要的是，`getColumnMeta`工作得非常好，它返回完整的表名，而不是 SQL 别名，MySQL 就是这种情况。如果我们用`$db = new PDO(‘sqlite:scott.sqlite’)`替换连接线，我们的两个 PDO 脚本都将完美工作。当然，开始和提交事务的命令是不需要的，但是它们也不会造成任何伤害。

#### PDO 的结论

PDO 有了一个良好的开端，但仍处于发展阶段。它将是 PHP 6 中唯一的数据库扩展，但这不会很快发生。对于利用标准的数据库特性来说，它已经足够了，但是它仍然不能利用几乎所有数据库中内置的专有数据库扩展，主要是因为性能原因。结合它功能不全的事实，我会建议读者把 PDO 扩展当作 beta 软件。

### ADOdb 简介

本书涉及的最后一个数据库扩展是 ADOdb。它是第三方扩展，根据 BSD 许可条款免费提供。大多数 Linux 发行版都将它作为一个软件包提供，其他的可以从这里下载:

`http://adodb.sourceforge.net`

安装包括将源文件解压到文件系统目录中。解压缩源代码的目录应该包含在该安装的 PHP.ini 参数中。

![images](img/square.jpg) **注意**需要将 ADOdb 解包的目录添加到 php.ini 文件中的`include_path` PHP 参数中，如果该目录还不存在的话。

ADOdb 模仿微软流行的 ActiveX 数据对象(ADO)框架。它支持异常、遍历数据库游标以及位置绑定和命名绑定。它还支持许多数据库，就像最初的 ADO 框架一样。MySQL、PostgreSQL、SQLite、Firebird、Oracle SQL Server、DB2 和 Sybase 等都受支持。它使用原始的数据库扩展，链接到 PHP 解释器中。如果 PHP 解释器支持 MySQL，就可以使用 ADOdb。换句话说，ADOdb 只是原始驱动程序之上的一个类结构。ADOdb 根据自己的选项设置驱动程序选项，但是数据库的原始驱动程序不是由 ADOdb 的作者 John Lim 提供的。

ADOdb 有两个版本:一个是旧版本，支持 PHP4 和 PHP5；另一个是新版本，只支持 PHP 5。本书中的例子已经用后一版本测试过了。乍一看，这两个版本看起来一模一样，如果需要支持 PHP4 的版本，还得单独下载。当然，PHP4 不支持异常，所以这部分不会和 PHP4 一起工作。

ADOdb 包含两个主要的类:连接类和结果类，即 ADOdb 文档中所称的 set 或 record set 类。

为了更好地解释事情，让我们看看两个脚本中的第一个，将 CSV 文件加载到数据库中的脚本(参见清单 8-5 )。

***清单 8-5。**将 CSV 文件载入数据库*

`<?php
require_once ('adodb5/adodb.inc.php');
require_once ('adodb5/adodb-exceptions.inc.php');
if ($argc != 3) {
    die("USAGE:script8.5 <table_name> <file name>\n");
}
$tname = $argv[1];
$fname = $argv[2];
$rownum = 0;
function create_insert_stmt($table, $ncols) {
    $stmt = "insert into $table values(";
    foreach (range(1, $ncols) as $i) {
        $stmt.= "?,";
    }
    $stmt = preg_replace("/,$/", ')', $stmt);
    return ($stmt);
}` `try {
    $db = NewADOConnection("mysql");
    $db->Connect("localhost", "scott", "tiger", "scott");
    $db->autoCommit = 0;
    $res = $db->Execute("select * from $tname");
    $ncols = $res->FieldCount();
    $ins = create_insert_stmt($tname, $ncols);
    $res = $db->Prepare($ins);
    $fp = new SplFileObject($fname, "r");
    $db->BeginTrans();
    while ($row = $fp->fgetcsv()) {
        if (strlen(implode('', $row)) == 0) continue;
        $db->Execute($res, $row);
        $rownum++;
    }
    $db->CompleteTrans();
    print "$rownum rows inserted into $tname.\n";
}
catch(Exception $e) {
    print "Exception:\n";
    die($e->getMessage() . "\n");
}
?>`

下面两行将把所有基本类加载到我们的脚本中。后面还会提到其他一些类:

`require_once ('adodb5/adodb.inc.php');
require_once ('adodb5/adodb-exceptions.inc.php');`

include 的确切位置将取决于 ADOdb 的安装。ADODB 发行版可以在系统上的任何地方解压缩，并且将同样工作，只要它由`include_path` PHP 指令正确指定。使用`NewADOConnection`函数创建新的 ADOdb 连接。它不是一个经典的 PHP 类构造函数；它只是一个返回连接类对象的函数。一旦创建了连接对象，就可以使用`Connect`方法连接到数据库。ADOdb 还包含在连接建立后关闭自动提交的调用。在这个脚本中这是不必要的，因为它控制它的事务——但是关闭自动提交没有任何害处，并且被认为是一个好的编程实践，如前所述。

注意，“`Execute`”方法属于连接类，而不属于记录集类。ADOdb 还必须执行语句，以便能够描述数据集，确定字段的数量以及它们的名称、类型和长度。使用前面显示的`FieldCount`方法确定字段的数量。绑定不是必需的；可以将绑定数组传递给执行调用，就像 PDO 的情况一样。再次值得注意的是，execute 方法在连接类中，而不是在结果集类中。Execute 方法其实很强大，支持数组执行。MySQL 不常执行数组，但 Oracle 或 PostgreSQL 经常执行数组，它们专门针对这种方法进行了优化。这是怎么回事？如果我们必须执行下面的 insert 语句:`$INS="insert into tab values(?,?)"`和一个如下所示的行数组:

`$rowbatch = array(
    array($a1,$a2),
    array($b1,$b2),
    array($c1,$c2));`

下面的调用实际上会插入所有三行，只执行一次:

`$db->Execute($INS,$rowbatch);`

像这样插入成批的记录会得到什么？首先，它最小化了网络通信，这仍然是应用中最慢的部分。如果有 100 行要插入，那么插入每一行本身就需要在网络上往返 100 次。如果以 20 行为一组插入行，只需要五次往返。此外，进程间的通信也大大减少了，因此数据库也不那么繁忙了。默认情况下，这个批量绑定特性是禁用的，必须通过设置“bulkBind”连接属性来激活，比如:`$db->bulkBind=true`。同样，这对于 MySQL 或 SQLite 来说没有多大意义，但是对于其他一些数据库来说却非常方便。

其他一切都是完全标准的，除了`CompleteTrans`方法，它很聪明，知道如果发生任何错误，它必须回滚事务。也有经典的提交和回滚方法，但是它们需要额外的逻辑来检查数据库错误。这是多余的，因为 ADOdb 会在出错时抛出异常，并且事务会在到达提交点之前死亡。此外，我们在 PostgreSQL 9.0 数据库上使用`CompleteTrans`时确实遇到了问题，当我们期望提交事务时，它执行了回滚。我们最终选择了`CommitTrans()`方法。有了 MySQL，就没有这些问题了。

现在，让我们看看我们的报告。SQL 现在已经广为人知；报告中唯一有趣的技巧是描述列和获取行(见清单 8-6 )。

***清单 8-6。**在此插入列表标题。*

`<?php
require_once ('adodb5/adodb.inc.php');
require_once ('adodb5/adodb-exceptions.inc.php');
$ADODB_FETCH_MODE = ADODB_FETCH_NUM;
$QRY = "select e.ename,e.job,d.dname,d.loc
        from emp e join dept d on(d.deptno=e.deptno)";
$colnames = array();
$ncols = 0;
try {
    $db = NewADOConnection("mysql");
    $db->Connect("localhost", "scott", "tiger", "scott");
    $res = $db->Execute($QRY);
    // Get the number of columns
    $ncols = $res->FieldCount();
    // Get the column names.
    foreach (range(0, $ncols - 1) as $i) {
        $info = $res->FetchField($i);
        $colnames[] = $info->name;
    }
    //  Print column titles, converted to uppercase.
    foreach ($colnames as $c) {
        printf("%-12s", strtoupper($c));
    }
    //  Print the boundary
    printf("\n%s\n", str_repeat("-", 12 * $ncols));` 
`    //  Print row data
    while ($row = $res->FetchRow()) {
        foreach ($row as $r) {
            printf("%-12s", $r);
        }
        print "\n";
    }
}
catch(Exception $e) {
    print "Exception:\n";
    die($e->getMessage() . "\n");
}
?>`

在清单 8-6 的最开始，有一行将`$ADODB_FETCH_MODE`变量设置为常量`ADODB_FETCH_NUM`。这是我们之前见过的相同机制的另一个版本。ADOdb 没有像 PDO 那样将返回值的期望形式作为参数传递，而是设置了一个特殊的全局变量，`FetchRow`方法会依次查询这个变量。就像 PDO 的情况一样，ADOdb 可以返回一个关联数组、一个数字索引数组，或者两者兼有。默认情况下，两者都返回。

描述列的方法是`FetchField`。它将列号作为参数，并返回具有以下属性的对象:name、type 和 max_length。以下是返回对象的示例:

`ADOFieldObject Object
(
    [name] => ename
    [max_length] => -1
    [type] => varchar
)`

从这个例子可以看出，max_length 字段不太准确，不应该依赖它。幸运的是，正如我们现在所知道的，PHP 是一种弱类型脚本语言，所以这不是一个大问题。

ADOdb 是一个大型库。它甚至有自己的缓存机制，虽然不如“memcached”包高效，但设置和使用起来非常简单。缓存基于文件系统缓存。结果被写入操作系统文件，以便下次请求查询时，只需从文件中读取结果。如果 web 服务器与数据库在不同的机器上，使用缓存来检索数据确实可以节省一些时间。此外，缓存是多用户的，所以如果几个用户正在执行一个类似的应用，结果文件将被缓存在内存中，性能的提升将是相当显著的。要定义缓存，只需通过设置相应的全局变量来定义缓存目录:

`$ADODB_CACHE_DIR="/tmp/adodb_cache";`

缓存目录可能会快速增长，应该位于通常由操作系统清理的位置，如/tmp 目录，如果系统是这样配置的，它会在系统重新启动时被完全清理。之后，通过调用`CacheExecute`方法而不是`Execute`方法来使用缓存:

`$res = $db->CacheExecute(900,$QRY);`

第一个参数定义了缓存失效的秒数。如果文件超过给定的秒数，将不会被使用。第二个参数是要执行的查询。这将在目录中创建一个如下所示的文件:

`ls -R /tmp/adodb_cache/
/tmp/adodb_cache/:
03

/tmp/adodb_cache/03:
adodb_03b6f957459e47bab0b90eb74ffaea68.cache`

子目录“03”基于查询的哈希值，由内部哈希函数计算。然后还有另一个哈希函数来计算文件名。如果文件名中的查询与脚本中的查询相同，则结果将从文件中检索，而不是从数据库中检索。

禁止绑定变量；只能缓存没有占位符的查询结果。这是一个可以理解的规定，因为查询结果依赖于绑定变量，而这些变量是在运行时提供的，这使得缓存不可能。在频繁变化的数据库中，业务需求要求数据必须完全准确和最新，因此不能使用这种缓存机制，但是对于频繁查询的相对静态的数据，这种机制非常有用。例如，日期不太可能在 24 小时内改变，这使得今天的日期成为缓存的理想候选。

#### ADOdb 结论

ADOdb 还有许多其他方法和技巧，但是涵盖所有这些超出了本书的范围。我们已经描述了最常用的，但是这个库非常全面。这是迄今为止我们见过的最大的库。它也在许多开源产品中使用，有很好的文档记录，并得到很好的支持。它还支持各种各样的数据库。

### 使用 Sphinx 进行全文搜索

文本搜索通常被认为是独立于数据库集成的一个主题，但是每个主要的数据库都有一个全文搜索引擎。Sphinx 恰好是 MySQL 数据库的默认全文搜索引擎。然而，在本书中，我将展示如何使用 PostgreSQL 设置和使用 Sphinx 来搜索文本，因为这是我们手头的数据库。

那么，什么是全文搜索，为什么需要它们？大多数现代数据库在正则表达式方面做得很好，所以人们会认为没有必要进行全文搜索。不幸的是，正则表达式的搜索通常不能使用索引，所以它们太慢了，不实用。这就是为什么有一种技术可以创建特殊的文本索引来帮助进行全文搜索。文本索引和附带的软件可以做以下事情:

*   单词搜索。这意味着搜索包含特定单词的记录，如“鸡肉”或“沙拉”
*   短语搜索。这是为用户寻找一个短语，如“鸡肉沙拉”，谁不一定想得到像“鸡翅和土豆沙拉”，这将是基于搜索两个单词，“鸡肉”和“沙拉”返回的东西
*   邻近搜索，也称为“邻近运算符”，检索给定文本字段包含的所有行，例如，单词“hello”和“world”彼此之间的距离不超过三个单词。
*   Quorum 搜索，这是一种搜索类型，其中有一个单词列表以及出现在文章中的最少数量的单词，这些单词将被标记为匹配。
*   逻辑运算符:您可以使用 AND、or 和 NOT 运算符组合搜索单词。

所有现代搜索引擎都有这样的能力。当然，不止一种文本搜索软件，既有开源的，也有商业的。开源文本引擎有 Sphinx、Lucene、Xapian 和 Tsearch2，它们各有优缺点。还有一些商业产品，如 Oracle*Text 或 Autonomy Corp .的 IDOL engine。本章的其余部分将专门介绍 Sphinx，这是一个由 Sphinx Technologies 开发的开源文本搜索引擎。公司网址为:`[`sphinxsearch.com`](http://sphinxsearch.com)`

安装很简单，该程序通常作为操作系统包提供。如果 Sphinx 还没有本机安装，那么它几乎可以在任何操作系统上构建。PHP 还需要一个额外的模块，通过使用 PECL 实用程序来安装。

Sphinx 由两部分组成:索引器，它构建所需的文本索引；和执行搜索的搜索过程。这两个组件都由名为`sphinx.conf`的配置文件控制。第一步是实际建立一个索引。Sphinx 索引器根据一些规则读取文档源并构建索引。文档源可以是数据库或产生 XML 的程序(“xmlpipe”)。支持的数据库有 PostgreSQL 和 MySQL。

用于演示 Sphinx 的数据库将是 PostgreSQL，这是一个非常强大的开源数据库。将用于索引的表称为 food_articles，是通过在 Google 上搜索食品文章组装而成的。有 50 篇文章，有作者、我们找到文章的 URL、文本和文章被收集的日期。所有的文章都是在 2011 年 1 月 30 日收集的，所以日期栏有点无聊。然而，这对于本书中的例子是必要的。

文章中的换行符被标记换行符的 HTML 标签替换。由于将数据加载到数据库中所使用的方法，这是一种不可避免的弊端。通过使用全能的“vi”编辑器，关于文章的所有信息被组装成一个大的 CSV 文件。然后将生成的 CSV 文件加载到数据库中。表 8-1 显示了食物 _ 物品表的样子。

![images](img/t0801.jpg)

文档 id 是主键，是文章的序号。它属于“bigint”类型，可以包含 64 位整数。现在，让我们继续构建我们的文本索引。文本索引是由名为“indexer”的程序构建的，它是 Sphinx 包的一部分。首先，我们需要配置文件，通常命名为`sphinx.conf`。文件的位置取决于您使用的操作系统。下面是我们相当典型的配置文件，由软件附带的示例文件构造而成:

***清单 8-7。**在此插入列表标题，*

`###################################################
## data source definition
###################################################

source food
{
        # data source type. mandatory, no default value
        # known types are mysql, pgsql, mssql, xmlpipe, xmlpipe2, odbc
        type                                    = pgsql
        sql_host                                = localhost
        sql_user                                = mgogala
        sql_pass                                = qwerty
        sql_db                                  = mgogala
        sql_port                                = 5432

        sql_query  = \
                SELECT document_id, \
                                    date_part('epoch',published) as publ_date, \
                                    article \
                        FROM   food_articles;
            sql_query_info = \
                SELECT document_id, \
                                    date_part('epoch',published) as publ_date, \
                                    article \
                       FROM   food_articles \
                      WHERE  document_id=$id;

    sql_attr_timestamp  = publ_date
}
index food-idx

{
        source                  = food
        path                    = /usr/local/var/data/food
        docinfo                 = extern
        charset_type            = utf-8
        preopen                 = 1

}` 
`indexer
{
    mem_limit                   = 256M
    write_buffer                 = 8M
    max_file_field_buffer   = 64M
}
searchd
{
    listen          = 9312
    log             = /var/log/searchd.log
    query_log       = /var/log/query.log
    read_timeout    = 5
    max_children    = 30
    pid_file        = /var/run/searchd.pid
    max_matches     = 1000
    seamless_rotate = 1
    preopen_indexes = 0
    unlink_old      = 1
    read_buffer     = 1M
    read_unhinted   = 256K
    subtree_docs_cache = 64M
    subtree_hits_cache = 64M
}`

这个文件的结构相当简单。第一部分定义了数据的来源。每个来源都有自己的名字；这个例子的来源叫做“食物”它首先定义数据库，包括数据库的类型、数据库名称、用户名、密码和端口——所有常见的东西。在源部分要定义的第二件事是如何获取数据。有两个查询:一个获取数据，另一个获取关于特定文档 id 的信息。Sphinx 期望选择列表的第一列是主键。它还期望主键是一个整数。它可以接受 64 位整数。

![images](img/square.jpg) **注意**Sphinx 数据源中查询的第一列必须是主键。主键也必须是整数。支持大的 64 位整数。

这就是将我们的 document_id 列定义为“bigint”的原因，尽管事实上只有 50 篇文章。还要注意，没有必要从表中选择所有的列。只选择需要索引的列将有助于节省时间和空间。之后，可以定义可选的属性。属性不是索引列。属性不能用于文本搜索；属性只能用于排序和范围搜索。我们可以要求 2 月份的数据，但由于样本数据的性质，我们不会得到任何数据。属性可以是数字或时间戳。时间戳被定义为从 1970 年 1 月 1 日开始的秒数。日期字段不能直接使用；它们必须被映射成纪元格式。

![images](img/square.jpg) **注意**由几行组成的字段，比如我们的 SQL 字段，必须像前面的例子一样使用反斜杠字符。

下一节是索引的定义。它必须包含将用于获取数据的数据源的名称、将写入索引文件的路径以及字符集类型。我们的索引还包含可选的性能参数“preopen”，它指示搜索过程在开始时打开索引，而不是等待第一次搜索。因此，第一次搜索会更快。

之后是索引器的内存选项，该程序用于建立文本索引和执行搜索的搜索过程。搜索过程的重要选项是“max_matches”选项。它定义了搜索过程可以返回的最大命中数。它可以找到更多的匹配，但它只能返回“max_matches”个匹配。在 PHP 中，这是搜索可以返回的最大数组大小。我们的配置文件准备好了；让我们建立一个索引。

`indexer food-idx
Sphinx 1.10-beta (r2420)
Copyright (c) 2001-2010, Andrew Aksyonoff
Copyright (c) 2008-2010, Sphinx Technologies Inc (http://sphinxsearch.com)

using config file '/usr/local/etc/sphinx.conf'...
indexing index 'food-idx'...
collected 50 docs, 0.2 MB
sorted 0.0 Mhits, 100.0% done
total 50 docs, 230431 bytes
total 0.038 sec, 5991134 bytes/sec, 1299.98 docs/sec
total 3 reads, 0.000 sec, 38.9 kb/call avg, 0.0 msec/call avg
total 9 writes, 0.000 sec, 31.6 kb/call avg, 0.0 msec/call avg`

调用程序“索引器”时将索引的名称作为参数；就这么简单。唯一重要的事情是编写配置文件。Sphinx 以其最快的索引构建程序而自豪。它真的非常快，当有许多项目需要索引时，这一点非常重要。创建索引后，必须开始搜索过程，只需从命令行执行命令`searchd`。在 Windows 中，有一个用于启动搜索过程的菜单。如果一切正常，该过程将如下所示开始:

`searchd
Sphinx 1.10-beta (r2420)
Copyright (c) 2001-2010, Andrew Aksyonoff
Copyright (c) 2008-2010, Sphinx Technologies Inc (http://sphinxsearch.com)

using config file '/usr/local/etc/sphinx.conf'...
listening on all interfaces, port=9312
precaching index 'food-idx'
precached 1 indexes in 0.001 sec`

现在，我们可以使用“搜索”程序来测试索引。搜索程序是一个命令行工具，它与搜索进程进行通信，并在命令行上执行传递给它的搜索。

`search "egg & wine"
Sphinx 1.10-beta (r2420)
Copyright (c) 2001-2010, Andrew Aksyonoff
Copyright (c) 2008-2010, Sphinx Technologies Inc (http://sphinxsearch.com)

using config file '/usr/local/etc/sphinx.conf'...
index 'food-idx': query 'egg & wine ': returned 2 matches of 2 total in 0.000 sec

displaying matches:
1\. document=9, weight=1579, publ_date=Sun Jan 30 00:00:00 2011
2\. document=36, weight=1573, publ_date=Sun Jan 30 00:00:00 2011

words:
1\. 'egg': 8 documents, 9 hits
2\. 'wine': 20 documents, 65 hits`

这个搜索寻找包含单词“egg”和“wine”的文档。它也给了我们关于它发现的文件的详细信息。现在是时候了解更多关于搜索的细节了:

*   搜索“egg | wine”将返回包含其中任何一个单词的所有文档。“|”字符是“或”逻辑运算符。
*   搜索“鸡蛋和葡萄酒”将返回包含这两个单词的文档。“&”字符是“与”逻辑运算符。
*   正在搜索“！egg”将返回所有不包含单词 egg 的文档。“！”字符是逻辑否定——“非”运算符。如果用于从命令行进行搜索，则必须在搜索文本周围使用单引号，因为感叹号对 shell 有特殊的意义，并且单引号中的字符不会被 shell 进一步解释。这只适用于 Linux 和 Unix shells，不适用于 Windows 命令行。
*   搜索“橄榄油”(双引号是表达式的一部分)将返回包含确切短语“橄榄油”的文档
*   搜索“olive oil”~ 5 将返回包含单词“olive”和“oil”的文档，单词之间的间隔不超过五个单词。
*   搜索“油醋番茄生菜沙拉”/3 将返回包含至少三个给定单词的文档。这就是所谓的“法定人数搜索”

这些是可以在复杂表达式中组合的基本运算。现在是时候写一个 PHP 脚本来搜索文本索引了。由于输出的大小和类型，这个脚本将在浏览器中使用，这意味着我们需要构建一个简单的 HTML 表单，并将输出显示为 HTML 表。这将通过使用两个 PEAR 模块来完成:HTML_Form 和 HTML_Table。HTML_Form 有点过时但是非常简单易用。该脚本如清单 8-8 所示。

***清单 8-8。**搜索文本索引(PHP 脚本)*

`<?php
/* ADOdb includes */
require_once ('adodb5/adodb.inc.php');
require_once ('adodb5/adodb-exceptions.inc.php');
$ADODB_FETCH_MODE = ADODB_FETCH_NUM;
$db = ADONewConnection("postgres8");
$colheaders = array("ID", "AUTHOR", "PUBLISHED", "URL", "ARTICLE");

/* PEAR modules are used for simplicity */
require_once ('HTML/Form.php');
require_once ('HTML/Table.php');
$attrs = array("rules" => "rows,cols", "border" => "3", "align" => "center");
$table = new HTML_Table($attrs);
$table->setAutoGrow(true);

/* Set the output table headers */
foreach (range(0, count($colheaders) - 1) as $i) {
    $table->setHeaderContents(0, $i, $colheaders[$i]);
}

/* Get the given document from the database */
$QRY = "select * from food_articles where document_id=?";
$srch = null;
if (!empty($_POST['srch'])) {
    $srch = trim($_POST['srch']);
}

/* Display a simple form, consisting only of a single textarea field */
echo "<center><h2>Sphinx Search</h2></center><hr>";
$form = new HTML_Form($_SERVER['PHP_SELF'], "POST");
$form->addTextarea("srch", 'Search:', $srch, 65, 12);
$form->addSubmit("submit", "Search");
$form->display();

/* Stop if there is nothing to search */
if (empty($srch)) exit;

try {
    $db->Connect("localhost", "mgogala", "qwerty", "mgogala");
    $stmt = $db->Prepare($QRY);
/* Connect to Sphinx "searchd" process */
    $cl = new SphinxClient();
    $cl->SetServer("localhost", 9312);
/* Set the extended mode search, for the phrase searches */
    $cl->SetMatchMode(SPH_MATCH_EXTENDED2);
/* Results will be ordered by date */
    $cl->SetSortMode(SPH_SORT_ATTR_DESC, "publ_date");` 
`/* Execute search  and check for problems */
    $result = $cl->Query($srch);
    if ($result === false) {
        throw new Exception($cl->GetLastError());
    } else {
        if ($cl->GetLastWarning()) {
            echo "WARNING: " . $cl->GetLastWarning() . "<br>";
        }
    }

/* Get the results and use them to query the database */
    foreach ($result["matches"] as $doc => $docinfo) {
        $rs = $db->Execute($stmt, array($doc));
        $row = $rs->FetchRow();
/* Add the result of the query to the output table */
        $table->addRow($row);
    }
/* Display the results */
    echo $table->toHTML();
}
catch(Exception $e) {
    die($e->getMessage());
}`

这个脚本比本章中其他地方的命令行片段更接近程序员通常需要的脚本。这个脚本使用 ADOdb、简单的 web 模块和 Sphinx 搜索引擎组合了数据库。输出显示在图 8-1 中。

![images](img/0801.jpg)

***图 8-1。**输出的脚本在清单 8-7 中*

该表单用于输入搜索词。当输入术语 search 时，脚本连接到数据库和 Sphinx 搜索引擎，并通过发出以下调用来检索数据:`$result=$cl->Query($search)`。Sphinx 将解析查询词并返回数据。结果是一个关联数组，如下所示:

`Array
(
    [error] =>
    [warning] =>
    [status] => 0
    [fields] => Array
        (
            [0] => article
        )

    [attrs] => Array
        (
            [publ_date] => 2
        )` 
`    [matches] => Array
        (
            [13] => Array
                (
                    [weight] => 2713
                    [attrs] => Array
                        (
                            [publ_date] => 1296363600
                        )

                )

        )

    [total] => 1
    [total_found] => 1
    [time] => 0
    [words] => Array
        (
            [celery] => Array
                (
                    [docs] => 3
                    [hits] => 4
                )

            [apple] => Array
                (
                    [docs] => 3
                    [hits] => 5
                )

            [soup] => Array
                (
                    [docs] => 13
                    [hits] => 30
                )

            [lentil] => Array
                (
                    [docs] => 1
                    [hits] => 3
                )

        )

)`

在 id=13 的文档中找到了与我们的搜索词匹配的内容。搜索词是“芹菜&苹果&汤&扁豆”我们在寻找包含所有这些词的文章。匹配被放在`$result['matches']`数组中，该数组也是一个包含带权重的文档信息的关联数组。权重是通过使用被称为“BM25”的统计函数来计算的，该函数考虑了词频。文档权重越高，匹配越好。文章本身并没有以可见的形式表现出来。为了获得文档 id=13 的行，我们需要访问数据库。这可能不太方便，但是在索引中复制数据库中的数据会浪费空间。当只有 50 条记录时，这并不重要，但是如果有数百万行，复制数据的成本会高得惊人。毕竟，数据已经驻留在数据库中，没有必要再将它存储到索引中。

Sphinx 是令人惊讶的多功能软件。它有实时索引，类似 SQL 查询的语法，它可以做“联合索引”，这意味着一个索引可以指向不同机器上的几个其他索引，它可以做 UTF-8，它可以访问不同的数据库。它的搜索语法非常灵活。Sphinx client 也内置在 MySQL 数据库中，但是如前所述，它实际上也可以与其他数据库一起工作。Sphinx 还可以模拟 MySQL，并用于将目标与 MySQL PHP 扩展、MySQL ODBC 驱动程序甚至 MySQL 命令行客户端连接起来。此外，PHP 客户端得到了很好的维护和记录。

### 总结

在本章中，我们讨论了以下主题:

*   关系型数据库
*   数据对象
*   ADOdb(收养数据库)
*   狮身人面像

MySQL 是一个成熟的关系数据库，有很多关于它的书籍。除了最后一节，本章的所有部分都基于 MySQL 数据库。就本章而言，数据库类型并不特别重要。PDO、ADOdb 和 Sphinx 也可以在 SQLite、PostgreSQL、Oracle 或 DB2 上演示。脚本看起来是一样的。当然，对于 Sphinx，我们需要一个脚本来读取数据库并为除 MySQL 或 PostgreSQL 之外的任何数据库编写 XML 文件，但这不是一个大问题。ADOdb 可以很好地用于这个目的。

本章不是全面的参考；这只是作为一个介绍。所有这些库和软件包都有本章没有描述的选项和可能性。